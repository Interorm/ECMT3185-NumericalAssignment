{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae7897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "with open('../../data/DatasetCleaned.csv', 'r') as f:\n",
    "    DATA = pd.read_csv(f)\n",
    "\n",
    "\n",
    "Y_DATA = np.log(DATA['SalePrice'].copy()).values\n",
    "VAR_DEPENDENT = 'SalePrice_log'\n",
    "\n",
    "X_DATA = DATA.copy().drop(columns=['SalePrice','Unnamed: 0'])\n",
    "\n",
    "\n",
    "def PrepX(X:pd.DataFrame, scaler_type=PowerTransformer(method='yeo-johnson'), \n",
    "          only_dummies:bool=False, fit:bool=False):\n",
    "\n",
    "    X_prep = pd.DataFrame(index=X.index)\n",
    "    X_types = X.dtypes.to_dict()\n",
    "\n",
    "    #Stores Scalers later in Dictionary (Column:Scaler)\n",
    "    if fit: scalers = {}\n",
    "    else: scalers = scaler_type\n",
    "\n",
    "    new_cols = []\n",
    "\n",
    "    #Iterates over X and applies transformations based on column type; Adds transformed columns \n",
    "    for col, t in X_types.items():\n",
    "\n",
    "        #Dummy columns and Percentages that don't need to be scaled (computed in Preperation.ipynb)\n",
    "        if t != 'object' and -1 <= X[col].min() and X[col].max() <= 1 and not only_dummies: \n",
    "            new_cols.append(X[col].copy().replace({-1:0})) \n",
    "            continue\n",
    "\n",
    "        #Transforms Numeric values; either builds scalers or applies them\n",
    "        if t in ['int', 'float'] and not only_dummies:\n",
    "            nonapplicable = X[col] == -1\n",
    "\n",
    "            new_col = X[col].copy()\n",
    "            applic_values = new_col.loc[~nonapplicable].values.reshape(-1, 1)\n",
    "\n",
    "            #If fit=True, construct a new scaler for the training data. Otherwise, use the SCALER dict to scale test data\n",
    "            if fit: \n",
    "                scaler = clone(scaler_type)\n",
    "                scaler.fit(applic_values)\n",
    "                scalers[col] = scaler\n",
    "                new_col.loc[~nonapplicable] = scaler.transform(applic_values).flatten()\n",
    "            else:\n",
    "                new_col.loc[~nonapplicable] = scalers[col].transform(applic_values).flatten()\n",
    "\n",
    "\n",
    "            new_col.loc[nonapplicable] = 0\n",
    "\n",
    "            new_cols.append(new_col)\n",
    "            \n",
    "            continue\n",
    "\n",
    "        #Create dummies for categorical (str) columns; with Validation set this is done before splitting\n",
    "        if t == 'object': \n",
    "            new_col = pd.get_dummies(X[col].copy(), prefix=col, drop_first=True, dtype=int)\n",
    "            new_cols.append(new_col)\n",
    "            continue\n",
    "\n",
    "        #This is only relevant when creating only dummies for the validation Set to not loose columns\n",
    "        if only_dummies and t != 'object':\n",
    "            X_prep[col] = X[col].copy()\n",
    "        else:\n",
    "            print(f'Type \\\"{t}\\\" not in standard types!')\n",
    "\n",
    "    if new_cols: X_prep = pd.concat([X_prep] + new_cols, axis=1)\n",
    "\n",
    "    if fit: return X_prep, scalers\n",
    "    else: return X_prep\n",
    "\n",
    "#Split data into train and validation set. \n",
    "# #train_test_split is not because before splitting we need to ensure that all dummy variables are present to not have missing columns in either set\n",
    "def Split(X:pd.DataFrame, Y:pd.DataFrame, TestSize:float, random_state:int=42):\n",
    "\n",
    "    X = PrepX(X_DATA, only_dummies=True, fit=False)\n",
    "\n",
    "    split_index = np.random.RandomState(random_state) \\\n",
    "                           .choice([True, False], size=len(Y), p=[TestSize,1-TestSize])\n",
    "    \n",
    "    X_test = X[split_index]\n",
    "    X_train = X[~split_index]\n",
    "    Y_test = Y[split_index]\n",
    "    Y_train = Y[~split_index]\n",
    "\n",
    "    return X_test, X_train, Y_test, Y_train\n",
    "\n",
    "\n",
    "VALIDATION_SET = True\n",
    "if VALIDATION_SET: \n",
    "    X_VAL, X_DATA, Y_VAL, Y_DATA = Split(X_DATA, Y_DATA, 0.05, 1)\n",
    "\n",
    "X_DATA, SCALER = PrepX(X=X_DATA, fit=True)\n",
    "VAR_NAMES = X_DATA.columns\n",
    "X_DATA = X_DATA.values.reshape(-1,X_DATA.shape[1])\n",
    "\n",
    "if VALIDATION_SET:\n",
    "    X_VAL = PrepX(X=X_VAL, scaler_type=SCALER)\n",
    "    X_VAL = X_VAL.values.reshape(-1, X_VAL.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a293210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def BootstrapLasso(Y, X, feature_names:list, alpha, n_bootstrap, display:bool=True):\n",
    "\n",
    "    n_obs = len(Y)\n",
    "\n",
    "    B = []\n",
    "    FailedReg = 0\n",
    "    for i in tqdm(range(0, n_bootstrap),\n",
    "                  desc='Fitting Lasso-Model with Bootstrapped Samples', unit='sample'):\n",
    "        sample_index = np.random.choice(range(0, n_obs), n_obs)\n",
    "\n",
    "        X_sample = X[sample_index]\n",
    "        Y_sample = Y[sample_index]\n",
    "\n",
    "        lasso = LassoCV(alphas=alpha, cv=KFold(), max_iter=100000)\n",
    "        lasso.fit(X_sample, Y_sample)        \n",
    "\n",
    "        if lasso.alpha_ == min(alpha): \n",
    "            FailedReg += 1\n",
    "            continue\n",
    "\n",
    "        coefs = {}\n",
    "        for i, var in enumerate(feature_names):\n",
    "            coefs[var] = lasso.coef_[i]\n",
    "\n",
    "        mse = np.mean((Y - lasso.predict(X))**2)\n",
    "\n",
    "        B.append({\n",
    "            'X_sample':X_sample,\n",
    "            'Y_sample':Y_sample,\n",
    "            'Sample_Key':sample_index,\n",
    "            'LassoModel':lasso,\n",
    "            'alpha':lasso.alpha_,\n",
    "            'r_squared':lasso.score(X_sample, Y_sample),\n",
    "            'r_squared_fullData':lasso.score(X, Y),\n",
    "            'coefficients':coefs,\n",
    "            'mse':mse,\n",
    "            'N Nonzero Estimators':sum([1 for key, item in coefs.items() if item != 0])\n",
    "        })\n",
    "\n",
    "\n",
    "    print(f'{FailedReg} failed regularizations')\n",
    "    return pd.DataFrame(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#with open('models/Bootstrapped_Lasso.sav', 'rb') as f: BootstrappedModels = pickle.load(f)\n",
    "with open('models/Lasso.sav', 'rb') as f: LassoOrig, ScalerOrig = pickle.load(f)\n",
    "\n",
    "#This takes about 30 Minutes to run\n",
    "BootstrappedModels = BootstrapLasso(Y_DATA, X_DATA, VAR_NAMES, alpha=np.logspace(-4,-2,200), n_bootstrap=1000)\n",
    "with open('models/Bootstrapping.sav', 'wb') as f: pickle.dump(BootstrappedModels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e027a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Coefficient_Boxplots(B_Coefficients:pd.Series, Lasso_Orig:LassoCV, var_names:list, cutoff:int=0.0):\n",
    "\n",
    "    relevant_cols = []\n",
    "    for i, var in enumerate(var_names):\n",
    "        values = np.array([B[var] for B in B_Coefficients])\n",
    "        if np.count_nonzero(values) / len(values) >= cutoff:\n",
    "            relevant_cols.append({'var':var, 'coefs':values, 'index':i})\n",
    "    \n",
    "    boxplot_rows = int(np.ceil(len(relevant_cols) / 5))\n",
    "    fig, axes = plt.subplots(boxplot_rows, 5, figsize=(15, 2*boxplot_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, var in zip(axes, relevant_cols):\n",
    "        ax.boxplot(var['coefs'], patch_artist=True)\n",
    "        ax.axhline(y = 0, color='black', ls = '--')\n",
    "        ax.axhline(y = Lasso_Orig.coef_[var['index']], color = 'red', ls=':')\n",
    "        ax.set_title(var['var'], fontsize=8)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862940fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coefficient_Boxplots(BootstrappedModels['coefficients'], LassoOrig, VAR_NAMES, 0.75)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
